{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticSiteScraper:\n",
    "    '''\n",
    "        Author: Retin P Kumar\n",
    "        Contact: retinpkumar@gmail.com\n",
    "        \n",
    "        Methods\n",
    "        =======\n",
    "        \n",
    "        url_parse\n",
    "        ---------\n",
    "        Returns the parsed html content of given url\n",
    "        \n",
    "        get_title\n",
    "        ---------\n",
    "        Returns the title of the given webpage\n",
    "        \n",
    "        get_all_links\n",
    "        -------------\n",
    "        Returns a list of all the links in the given url\n",
    "        \n",
    "        get_all_image_links\n",
    "        -------------------\n",
    "        Returns a list of all the links of images in the given url\n",
    "        \n",
    "        download_images\n",
    "        ---------------\n",
    "        Checks for an \"images\" directory within the current working directory.\n",
    "        If not found, creates an \"images\" directory in the current working \n",
    "        directory. Saves all the images from the links returned by get_all_image_links\n",
    "        method.       \n",
    "    '''\n",
    "    # importing libraries\n",
    "    import os\n",
    "    import datetime\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    \n",
    "    def __init__(self, url: str, parser: str='html.parser'):\n",
    "        '''\n",
    "            Parameters\n",
    "            ----------\n",
    "            url: url of webpage\n",
    "            parser: object for parsing text files\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            self: object\n",
    "        '''\n",
    "        self.url = url\n",
    "        self.parser = parser\n",
    "    \n",
    "    def url_parse(self): \n",
    "        '''\n",
    "        A method for parsing the url\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            self: object\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            self.soup: parsed web html content\n",
    "        '''\n",
    "        try:\n",
    "            # getting response from webpage\n",
    "            data = self.requests.get(self.url).text\n",
    "            # creating a html parsed object\n",
    "            self.soup = self.bs(data, self.parser)\n",
    "            return self.soup\n",
    "        except Exception as e:\n",
    "            print(\"Url not parsable. \", e)\n",
    "        finally:\n",
    "            # printing a prettified version of parsed html content\n",
    "            print(self.soup.prettify())\n",
    "    \n",
    "    def get_title(self):\n",
    "        '''\n",
    "        A method for fetching the page title\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            self: object\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            title: webpage title text\n",
    "        '''\n",
    "        try:\n",
    "            # fetching the webpage title\n",
    "            title = self.soup.title.text\n",
    "            print(title)\n",
    "        except:\n",
    "            print(\"Cannot find title.\")\n",
    "            \n",
    "    def get_all_links(self):\n",
    "        '''\n",
    "        A method for fetching all links from the webpage\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            self: object\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            links: list of all links in the given url\n",
    "        '''\n",
    "        links=[] # list to store all the links\n",
    "        try:\n",
    "            # fetching all <a> tags\n",
    "            self.a_tags = self.soup.find_all('a')\n",
    "        except:\n",
    "            print(\"Cannot find all <a> tags\")\n",
    "        \n",
    "        # iterating through each element in the list of <a> tags\n",
    "        for tag in self.a_tags:\n",
    "            items = str(tag).split(\" \")\n",
    "            for item in items:\n",
    "                if 'href' in item:\n",
    "                    link_item = item.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                    if 'http' in link_item or 'www' in link_item:\n",
    "                        links.append(link_item)\n",
    "        return links\n",
    "            \n",
    "    def get_all_image_links(self):\n",
    "        '''\n",
    "        A method for fetching all image links from the webpage\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            self: object\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            self.img_links: list of all image links in the given url\n",
    "        '''\n",
    "        self.img_links=[] # list to store all images\n",
    "        \n",
    "        # iterating through each element in the list of images\n",
    "        img_tags = self.soup.find_all('img')\n",
    "        for tag in img_tags:\n",
    "            items = str(tag).split(\" \")\n",
    "            for item in items:\n",
    "                if 'src' in item:\n",
    "                    link_item = item.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                    if 'http' in link_item or 'www' in link_item:\n",
    "                        self.img_links.append(link_item)\n",
    "        return self.img_links\n",
    "        \n",
    "    def download_images(self, image_list):\n",
    "        '''\n",
    "        A method for downloading images from the image links\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            self: object\n",
    "            image_list: list of image links\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            Images in the image links inside an 'images' directory within current\n",
    "            working directory.\n",
    "        '''\n",
    "        self.image_list = image_list\n",
    "        try:\n",
    "            # fetching today's date for directory name\n",
    "            day = self.datetime.date.today().day\n",
    "            month = self.datetime.date.today().month\n",
    "            year = self.datetime.date.today().year\n",
    "\n",
    "            date_ = str(day)+\"-\"+str(month)+\"-\"+str(year)+\"_\"\n",
    " \n",
    "            # creating a new directory to store images\n",
    "            if 'images' not in self.os.listdir():\n",
    "                self.os.mkdir(\"images\")\n",
    "                self.os.chdir(\"images\")\n",
    "            \n",
    "            self.os.mkdir(date_)\n",
    "            self.os.chdir(date_)\n",
    "            \n",
    "            #image number\n",
    "            img_no = 1\n",
    "                \n",
    "            # iterating through list of image links\n",
    "            for link in self.image_list:\n",
    "                # fetching image from webpage\n",
    "                img_response = self.requests.get(link)\n",
    "                \n",
    "                #file format\n",
    "                img_format = link.split(\".\")[-1]\n",
    "                \n",
    "                # creating a filename to store the image\n",
    "                filename = \"img\" + str(img_no) + \".\" + img_format\n",
    "                \n",
    "                # saving the image using the filename\n",
    "                with open(filename, \"wb+\") as f:\n",
    "                    f.write(img_response.content)\n",
    "                img_no += 1\n",
    "                \n",
    "            print(f\"{len(self.img_links)} images downloaded succesfully into 'images/{date_}' directory.\")    \n",
    "        except Exception as e:\n",
    "            print(\"Error while downloading images: \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
